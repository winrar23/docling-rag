# Product Requirements Document: Векторное хранилище документации на базе Docling

**Версия:** 1.0
**Дата:** 14 февраля 2026
**Автор:** Danny
**Статус:** В разработке (MVP)

---

## 1. Problem Statement (Описание проблемы)

Инженеры по разработке DWH (Data Warehouse) работают со сложной технической документацией, которая содержит архитектурные схемы, ER-модели, таблицы, SQL-код и текстовые описания. В настоящее время отсутствует централизованное хранилище знаний, что приводит к следующим проблемам:

- **Разрозненность информации:** Документация разбросана по разным папкам, системам и форматам, что затрудняет поиск нужной информации и приводит к потере времени
- **Низкое качество работы AI без контекста:** Существующие AI-ассистенты не могут эффективно отвечать на специфические технические вопросы без доступа к внутренней документации компании
- **Сложность обработки технических форматов:** Стандартные решения для работы с документами плохо справляются с извлечением информации из диаграмм, таблиц, SQL-кода и ER-моделей

**Стоимость бездействия:**
- Инженеры тратят 2-3 часа в день на поиск технической информации в документации
- AI-инструменты используются неэффективно, так как не имеют доступа к корпоративным знаниям
- Повторяющиеся вопросы остаются без быстрых ответов, замедляя разработку

**Доказательства:**
- Личный опыт: ежедневный поиск по техническим документам занимает значительное время
- Потребность в RAG-системе для улучшения качества работы с AI

---

## 2. Goals (Цели)

### Пользовательские цели:
1. **Мгновенный доступ к знаниям:** Пользователь может найти нужную техническую информацию за 5 секунд вместо 2-3 часов поиска по файлам
2. **Высокая точность ответов:** AI предоставляет релевантные ответы в 80%+ случаев на основе загруженной документации
3. **Поддержка технических форматов:** Система корректно обрабатывает и индексирует таблицы, SQL-код, структурированный текст. Диаграммы и ER-модели — через OCR (MVP) и Vision LLM (этап 2)

### Бизнес-цели:
1. **Повышение продуктивности:** Сокращение времени на поиск информации на 70%
2. **Масштабируемость знаний:** Создание фундамента для централизованного хранилища технических знаний компании
3. **Ежедневное использование:** Система становится основным инструментом работы с документацией (ежедневные обращения)

---

## 3. Non-Goals (Что НЕ входит в scope)

1. **Веб-интерфейс и многопользовательский доступ** — MVP представляет собой консольное приложение для одного пользователя. Веб-интерфейс и командная работа планируются на этапе 2.

2. **Интеграция с внешними системами (Confluence, SharePoint, Jira)** — MVP работает только с локальными файлами. Интеграции с корпоративными системами будут добавлены позже.

3. **Автоматическое обновление документации** — Система не отслеживает изменения в файлах автоматически. Пользователь должен вручную переиндексировать измененные документы.

4. **Семантическое понимание изображений (диаграммы, ER-модели)** — MVP обрабатывает только текстовый контент. Архитектурные схемы и ER-модели обрабатываются исключительно через встроенный OCR Docling (если применимо), но не через Vision LLM. Полноценный анализ изображений — этап 2.

5. **Продвинутая аналитика использования** — Логирование базовое (какие документы используются), но не будет дашбордов и детальной аналитики.

6. **Поддержка документов объемом более 100 файлов в MVP** — Фокус на малом объеме для проверки концепции. Масштабирование на 1000+ документов будет в этапе 2 с БД.

---

## 4. MVP Scope: Максимально простая версия (Docling + минимум зависимостей)

### Философия MVP

Этот проект следует принципу "максимально простого MVP" — используется минимальный набор технологий для достижения цели (семантический поиск по документации). Цель: проверить гипотезу о полезности RAG-системы за 2-3 недели с минимальными затратами.

### Минимальный технологический стек

```
Docling               # Парсинг документов (PDF, DOCX, etc.)
Sentence Transformers # Локальные эмбеддинги (all-MiniLM-L6-v2)
NumPy                 # Векторные операции и cosine similarity
Click                 # CLI интерфейс
```

**Всего: 4 библиотеки** (+ их зависимости)

### Что ВХОДИТ в MVP (Минимальная функциональность)

#### ✅ Парсинг документов через Docling
- Поддержка форматов: PDF, DOCX, MD, TXT
- Извлечение текста с сохранением структуры
- Базовая обработка таблиц (как текст)
- OCR для отсканированных PDF (если встроено в Docling)

#### ✅ Простая векторизация
- Локальная embedding-модель `all-MiniLM-L6-v2` (384 dimensions)
- Chunking документов на фрагменты 500-1000 токенов
- Сохранение эмбеддингов в `.npy` файлы (NumPy arrays)

#### ✅ Семантический поиск
- Cosine similarity для поиска ближайших векторов
- Возврат топ-5 результатов с score
- Линейный поиск (без индексации) — достаточно для 100 документов

#### ✅ CLI интерфейс
- `docling-rag init` — инициализация хранилища
- `docling-rag add <path>` — добавление документов
- `docling-rag search "<query>"` — поиск
- `docling-rag list` — список документов

### Что НЕ ВХОДИТ в MVP (Сознательные ограничения)

#### ❌ НЕТ продвинутых векторных хранилищ
- **Не используется:** FAISS, ChromaDB, Pinecone, Weaviate
- **Причина:** Избыточная сложность для 100 документов
- **Альтернатива:** Простое NumPy хранилище с линейным поиском
- **Ограничение:** Медленно при >500 документах (но для MVP — достаточно)

#### ❌ НЕТ базы данных
- **Не используется:** PostgreSQL, SQLite, MongoDB
- **Причина:** Файловое хранилище проще для MVP
- **Альтернатива:** JSON для метаданных, .npy для векторов
- **Ограничение:** Нет транзакций, сложно масштабировать

#### ❌ НЕТ LLM интеграции
- **Не используется:** OpenAI API, Anthropic API, локальные LLM
- **Причина:** MVP фокусируется только на поиске, не на генерации ответов
- **Альтернатива:** Возврат фрагментов документов "как есть"
- **Ограничение:** Пользователь сам читает найденные фрагменты

#### ❌ НЕТ сложной обработки изображений
- **Не используется:** GPT-4 Vision, LLaVA, BLIP
- **Причина:** Дорого и сложно для MVP
- **Альтернатива:** Базовый OCR (если есть в Docling) или игнорирование изображений
- **Ограничение:** Диаграммы и схемы обрабатываются только текстом из OCR

#### ❌ НЕТ продвинутого chunking
- **Не используется:** Semantic chunking, recursive splitting, context-aware splitting
- **Причина:** Простая стратегия работает для MVP
- **Альтернатива:** Фиксированный размер chunks с overlap
- **Ограничение:** Границы chunks могут разрывать смысловые блоки

#### ❌ НЕТ мониторинга и аналитики
- **Не используется:** Дашборды, метрики использования, A/B тесты
- **Причина:** Раннее для MVP
- **Альтернатива:** Базовое логирование в файл
- **Ограничение:** Сложно оценить эффективность количественно

### Технические ограничения MVP

| Аспект | Ограничение | Причина | Когда снять |
|--------|-------------|---------|-------------|
| **Объем данных** | До 100 документов | Линейный поиск медленный | Этап 2: FAISS |
| **Скорость поиска** | 2-5 секунд | Без индексации | Этап 2: Векторный индекс |
| **Точность эмбеддингов** | 384 dimensions | Малая модель | Этап 2: Большая модель |
| **Форматы изображений** | Только OCR текст | Нет Vision AI | Этап 2: GPT-4V |
| **Многоязычность** | Русский + English | Модель поддерживает | N/A (уже работает) |
| **Concurrent users** | 1 пользователь | Файловое хранилище | Этап 2: БД |
| **Обновления индекса** | Полная переиндексация | Нет инкрементальных обновлений | Этап 2: БД |

### Архитектура MVP (модульная структура)

```
docling-rag/
├── cli/                     # CLI команды (Click)
├── core/
│   ├── parser.py            # Docling парсер
│   ├── chunker.py           # Разбиение на chunks (без LangChain)
│   ├── embedder.py          # Sentence Transformers (all-MiniLM-L6-v2)
│   └── storage.py           # Абстракция хранилища
├── storage/
│   └── file_storage.py      # NumPy-хранилище (MVP)
├── data/
│   ├── embeddings.npy       # Матрица эмбеддингов (N × 384)
│   ├── metadata.json        # Метаданные chunks
│   └── documents/           # Оригинальные файлы
├── skills/                  # Skills для AI-агентов (P1)
├── tests/                   # Тесты
├── config.yaml              # Конфигурация
└── logs/
    └── search.log           # Логи запросов
```

### Почему этот подход работает для MVP

1. **Быстрый старт:** 2-3 недели от идеи до работающего продукта
2. **Минимум зависимостей:** Только 4 библиотеки, все бесплатны и работают локально
3. **Проверка гипотезы:** Можно оценить, нужна ли вообще RAG-система
4. **Легкий апгрейд:** Архитектура позволяет заменить NumPy на FAISS без переписывания всего
5. **Без внешних API:** Работает оффлайн, нет затрат на API

### Стратегия перехода к Этапу 2

После успешного MVP (достижение метрик: 80% точность, ежедневное использование):

**Переход на продвинутый стек:**
```
NumPy storage      → FAISS / ChromaDB       (быстрый поиск)
all-MiniLM-L6-v2   → text-embedding-3-large (лучшая точность)
Файлы              → PostgreSQL + pgvector  (масштабирование)
Только поиск       → + LLM генерация ответов (улучшенный UX)
```

**Миграция:**
- Эмбеддинги и метаданные легко экспортируются из .npy/.json в БД
- CLI остается, добавляется веб-интерфейс
- Обратная совместимость: старые команды работают

---

## 5. User Stories (Пользовательские сценарии)

### Приоритет P0 (Must-Have):

**US-1: Загрузка и индексация документов**
- **Как** DWH-инженер
- **Я хочу** загрузить техническую документацию (PDF, Word, Markdown) в систему через консольную команду
- **Чтобы** все мои документы были проиндексированы и доступны для семантического поиска

**US-2: Семантический поиск по документации**
- **Как** DWH-инженер
- **Я хочу** ввести текстовый запрос на естественном языке через консоль
- **Чтобы** получить список наиболее релевантных фрагментов документации с указанием источников

**US-4: Работа с SQL-кодом в документации**
- **Как** DWH-инженер
- **Я хочу** искать и получать фрагменты SQL-кода из документации по описанию задачи
- **Чтобы** быстро находить примеры запросов и не писать типовой код заново

### Приоритет P1 (Should-Have):

**US-5: Просмотр контекста найденных фрагментов**
- **Как** DWH-инженер
- **Я хочу** видеть расширенный контекст вокруг найденного фрагмента (предыдущие и следующие абзацы)
- **Чтобы** лучше понимать контекст информации без открытия исходного файла

**US-6: Обновление индекса при изменении документов**
- **Как** DWH-инженер
- **Я хочу** переиндексировать конкретный документ после его изменения
- **Чтобы** поиск всегда возвращал актуальную информацию

### Приоритет P2 (Future Considerations):

**US-7: Генерация ответов с использованием LLM**
- **Как** DWH-инженер
- **Я хочу** не только получать фрагменты документов, но и генерировать развернутые ответы на вопросы с помощью AI
- **Чтобы** не читать весь контекст самостоятельно, а получать готовые ответы

**US-8: История запросов**
- **Как** DWH-инженер
- **Я хочу** просматривать историю моих предыдущих запросов
- **Чтобы** быстро повторять часто используемые поисковые сценарии

**US-3: Извлечение информации из архитектурных диаграмм и ER-моделей**
- **Как** DWH-инженер
- **Я хочу** чтобы система извлекала структурированные данные из архитектурных диаграмм и ER-моделей
- **Чтобы** получать ответы на основе визуальных схем, а не только текстовых описаний
- **Примечание:** Требует Vision LLM (GPT-4V, LLaVA) — планируется на этап 2

---

## 6. Requirements (Требования)

### Must-Have (P0) — Минимально жизнеспособный продукт

#### R-1: Консольное приложение с командами
**Описание:** Система представляет собой CLI (Command-Line Interface) приложение с набором команд для работы с документацией.

**Acceptance Criteria:**
- [ ] Команда `docling-rag init` создает новое хранилище в указанной директории
- [ ] Команда `docling-rag add <path>` добавляет файлы/папки в индекс
- [ ] Команда `docling-rag search "<query>"` выполняет семантический поиск
- [ ] Команда `docling-rag list` показывает список проиндексированных документов
- [ ] Все команды возвращают понятные сообщения об ошибках при неверных параметрах

**Технические детали:** Python 3.10+, использование библиотеки `click` или `argparse` для CLI

---

#### R-2: Поддержка форматов документов через Docling
**Описание:** Система должна использовать всю функциональность библиотеки Docling для обработки сложных технических документов.

**Acceptance Criteria:**
- [ ] Поддержка форматов: PDF, DOCX, MD, TXT
- [ ] Извлечение текста с сохранением структуры (заголовки, списки, параграфы)
- [ ] Извлечение таблиц с сохранением структуры данных
- [ ] Распознавание изображений (диаграммы, схемы) с использованием OCR или image-to-text моделей
- [ ] Извлечение блоков кода (SQL, Python) с сохранением синтаксиса

**Технические детали:**
- Использование Docling API для парсинга документов
- Настройка Docling для оптимальной обработки технических документов
- Обработка ошибок при неподдерживаемых файлах

---

#### R-3: Векторное хранилище на файловой системе
**Описание:** Эмбеддинги и метаданные документов хранятся в локальной файловой системе без использования БД (MVP).

**Acceptance Criteria:**
- [ ] Векторные эмбеддинги сохраняются в формате, позволяющем быстрый поиск
- [ ] Метаданные (имя файла, путь, дата индексации) хранятся вместе с эмбеддингами
- [ ] Система создает индексную структуру папок автоматически при инициализации
- [ ] Данные хранятся в формате, который можно перенести в БД на этапе 2 без потери информации

**Технические детали:**
- Эмбеддинги хранятся в формате `.npy` (NumPy matrix, N × 384)
- Метаданные chunks хранятся в `metadata.json` рядом с `.npy` файлом
- Абстракция `storage.py` спроектирована так, чтобы файловое хранилище можно было заменить на PostgreSQL + pgvector на этапе 2 без изменения вызывающего кода

---

#### R-4: Семантический поиск с использованием эмбеддингов
**Описание:** Система преобразует запрос пользователя в вектор и находит наиболее релевантные фрагменты документации.

**Acceptance Criteria:**
- [ ] Запрос пользователя преобразуется в эмбеддинг той же моделью, что использовалась для индексации
- [ ] Система возвращает топ-5 наиболее релевантных фрагментов с указанием score
- [ ] Каждый результат содержит: фрагмент текста, название файла, номер страницы (если применимо)
- [ ] Время ответа на запрос — менее 5 секунд для хранилища из 100 документов

**Технические детали:**
- Embedding-модель: `all-MiniLM-L6-v2` (Sentence Transformers, локальная, бесплатная, 384 dimensions)
- Cosine similarity для поиска ближайших векторов (NumPy `np.dot`)
- Chunk size: 500-1000 токенов с overlap 100 токенов

---

#### R-5: Chunking (разбиение на фрагменты) документов
**Описание:** Документы разбиваются на логические фрагменты (chunks) для эффективной индексации и поиска.

**Acceptance Criteria:**
- [ ] Текст разбивается на chunks размером 500-1000 токенов
- [ ] Chunks имеют overlap (перекрытие) 10-15% для сохранения контекста на границах
- [ ] Таблицы и блоки кода не разбиваются, а обрабатываются как отдельные chunks
- [ ] Каждый chunk содержит метаданные: source_file, chunk_id, page_number

**Технические детали:**
- Собственный простой chunker (без LangChain): разбивка по предложениям с накоплением до целевого размера
- Специальная логика для таблиц и кодовых блоков: определяются по типу Docling-элемента, не разбиваются

---

### Should-Have (P1) — Важные улучшения для быстрого follow-up

#### R-6: Skills для работы с AI
**Описание:** Инструкции для работы с системой оформлены в виде skills, которые могут использовать AI-агенты. Создаются после того, как основной функционал (init/add/search) работает и протестирован.

**Acceptance Criteria:**
- [ ] Созданы skill-файлы в формате Markdown с инструкциями для AI
- [ ] Skills описывают команды CLI и ожидаемые результаты
- [ ] Skills содержат примеры использования для типовых сценариев
- [ ] Skills могут быть интегрированы в AI-агент (например, Claude Code)

**Технические детали:**
- Формат skills совместим с Claude Code / другими AI-платформами
- Документация по использованию skills в README

---

#### R-7: Поддержка переиндексации отдельных файлов
**Описание:** Возможность обновить индекс для конкретного файла без полной переиндексации.

**Acceptance Criteria:**
- [ ] Команда `docling-rag update <file_path>` обновляет только указанный файл
- [ ] Старые chunks файла удаляются из индекса перед добавлением новых
- [ ] Время переиндексации одного файла — менее 10 секунд

---

#### R-8: Конфигурационный файл
**Описание:** Настройки системы хранятся в конфигурационном файле.

**Acceptance Criteria:**
- [ ] Файл `config.yaml` содержит настройки: embedding_model, chunk_size, overlap, top_k_results
- [ ] Пользователь может изменить настройки без изменения кода
- [ ] При отсутствии конфига используются значения по умолчанию

---

### Could-Have (P2) — Будущие возможности

#### R-9: Интеграция с LLM для генерации ответов
**Описание:** Система не только находит фрагменты, но и генерирует развернутые ответы на вопросы.

**Технические детали:** Интеграция с OpenAI API или локальными LLM (Ollama, LM Studio)

---

#### R-10: Миграция на PostgreSQL + pgvector
**Описание:** Переход с файлового хранилища на реляционную БД с векторным расширением.

**Технические детали:**
- Использование PostgreSQL с расширением pgvector
- Поддержка обоих режимов работы (файлы и БД) одновременно
- Миграционный скрипт для переноса данных из файлов в БД

---

## 7. Success Metrics (Метрики успеха)

### Leading Indicators (Быстрые метрики)

**M-1: Покрытие документации**
- **Цель:** 100% загруженных файлов успешно проиндексированы
- **Измерение:** Отношение успешно обработанных файлов к общему количеству загруженных
- **Время оценки:** Сразу после индексации
- **Success threshold:** 95%+ файлов обработаны без ошибок

**M-2: Скорость ответа системы**
- **Цель:** Менее 5 секунд от запроса до получения результатов
- **Измерение:** Время выполнения команды `search` (логирование)
- **Время оценки:** При каждом запросе
- **Success threshold:** 90% запросов выполняются за < 5 сек

**M-3: Точность ответов**
- **Цель:** 80%+ запросов возвращают релевантные результаты
- **Измерение:** Ручная оценка первых 50 запросов (релевантны ли топ-3 результата?)
- **Время оценки:** Через 1 неделю использования
- **Success threshold:** 80% запросов имеют хотя бы 1 релевантный результат в топ-3

### Lagging Indicators (Долгосрочные метрики)

**M-4: Частота использования**
- **Цель:** Система используется ежедневно
- **Измерение:** Количество запросов в день (логирование команд)
- **Время оценки:** Через 1 месяц после запуска MVP
- **Success threshold:** 5+ запросов в день

**M-5: Сокращение времени на поиск информации**
- **Цель:** Уменьшение времени поиска технической информации на 70%
- **Измерение:** Субъективная оценка до/после внедрения (самооценка или опрос)
- **Время оценки:** Через 1 месяц
- **Success threshold:** Среднее время поиска снизилось с 2-3 часов до 30-45 минут в день

---

## 8. Open Questions (Открытые вопросы)

### Блокирующие вопросы (нужно решить до начала разработки):

**Q-1: Какую embedding-модель использовать?** ✅ Решено
- **Решение:** Sentence Transformers `all-MiniLM-L6-v2` — бесплатно, работает локально, поддерживает русский язык
- **Отклонено:** OpenAI `text-embedding-3-small` — платно, требует API-ключ, нет офлайн-режима

**Q-2: Как обрабатывать изображения (диаграммы, схемы)?** ✅ Решено
- **Решение для MVP:** Использовать встроенный OCR Docling для извлечения текста из изображений. Архитектурные диаграммы и ER-модели — в Non-Goals MVP.
- **Этап 2:** Vision LLM (GPT-4V, LLaVA) для семантического понимания схем

### Неблокирующие вопросы (можно решить в процессе):

**Q-4: Нужно ли логирование всех запросов для анализа?**
- **Кто решает:** Product + Engineering
- **Рекомендация:** Да, минимальное логирование (timestamp, query, top_result_score) для метрик

**Q-5: Поддерживать ли русский и английский языки одновременно?**
- **Кто решает:** Product
- **Рекомендация:** Да, использовать многоязычную embedding-модель

---

## 9. Timeline Considerations (Временные рамки)

### Этап 1: MVP (файловое хранилище)
**Сроки:** 2-3 недели разработки

**Milestone 1.1 (неделя 1):** Базовая функциональность
- Парсинг документов через Docling
- Chunking и создание эмбеддингов
- Файловое хранилище индекса

**Milestone 1.2 (неделя 2):** CLI и поиск
- Реализация команд CLI (`init`, `add`, `search`, `list`)
- Семантический поиск с выводом результатов
- Базовое логирование

**Milestone 1.3 (неделя 3):** Skills и тестирование
- Создание skills для AI-агентов
- Тестирование на 50-100 документах
- Документация (README, инструкции)

### Этап 2: БД и масштабирование (планируется позже)
**Сроки:** TBD (после успешного MVP)

- Интеграция с PostgreSQL + pgvector
- Поддержка 1000+ документов
- Веб-интерфейс (опционально)

---

## 10. Архитектурные решения

### Модульная структура проекта

```
docling-rag/
├── cli/                  # CLI-команды (add, search, init, etc.)
├── core/
│   ├── parser.py         # Docling-парсер документов
│   ├── chunker.py        # Разбиение на chunks
│   ├── embedder.py       # Генерация эмбеддингов
│   └── storage.py        # Абстракция хранилища (файлы / БД)
├── storage/
│   ├── file_storage.py   # Файловое хранилище (MVP)
│   └── db_storage.py     # БД-хранилище (этап 2)
├── skills/               # Skills для AI-агентов
├── tests/                # Тесты
├── config.yaml           # Конфигурация
└── README.md
```

### Ключевые технологии

**Этап 1 (MVP):**
- **Python 3.10+**
- **Docling** — парсинг документов (PDF, DOCX, MD, TXT)
- **Sentence Transformers** (`all-MiniLM-L6-v2`) — локальные эмбеддинги
- **NumPy** — хранение векторов (`.npy`) и cosine similarity
- **Click** — CLI интерфейс

**Этап 2 (планируется):**
- **ChromaDB / FAISS** — быстрый векторный поиск
- **PostgreSQL + pgvector** — масштабируемое хранилище
- **OpenAI / Anthropic API** — генерация ответов через LLM

---

## 11. Риски и Mitigation

### Риск 1: Docling плохо обрабатывает специфические форматы
**Вероятность:** Средняя
**Воздействие:** Высокое
**Mitigation:** Провести proof-of-concept на 10 реальных документах до начала разработки. Если Docling не подходит, рассмотреть альтернативы (Unstructured, PyMuPDF + custom parsers)

### Риск 2: Embedding-модель дает низкую точность на технических текстах
**Вероятность:** Средняя
**Воздействие:** Высокое
**Mitigation:** Протестировать 2-3 модели (OpenAI, Sentence Transformers, Cohere) на тестовом наборе из 20 запросов. Выбрать модель с лучшей точностью.

### Риск 3: NumPy хранилище не масштабируется на 100+ документов
**Вероятность:** Низкая
**Воздействие:** Среднее
**Mitigation:** Линейный поиск по NumPy матрице легко справляется с 100 документами (тысячи векторов). Скорость деградирует при >500 docs — но это MVP-ограничение, явно задокументированное в Non-Goals. На этапе 2 — переход на ChromaDB/FAISS или pgvector.

### Риск 4: Skills не интегрируются с AI-агентами
**Вероятность:** Низкая
**Воздействие:** Среднее
**Mitigation:** Использовать проверенный формат skills (Markdown с примерами), совместимый с Claude Code и другими платформами.

---

## Заключение

Данная спецификация описывает минимально жизнеспособный продукт (MVP) векторного хранилища документации для DWH-инженеров на базе библиотеки Docling. Фокус MVP — на семантическом поиске по техническим документам с поддержкой сложных форматов (диаграммы, таблицы, код).

После успешного запуска MVP и достижения метрик (80% точность, ежедневное использование, 100% покрытие документации) планируется этап 2: миграция на PostgreSQL + pgvector, масштабирование на 1000+ документов, и возможная интеграция с LLM для генерации ответов.

---

**Следующие шаги:**
1. Провести proof-of-concept на 10 реальных документах (проверить Docling на целевых форматах)
2. Начать разработку MVP согласно timeline (неделя 1: parser + chunker + embedder + file_storage)
